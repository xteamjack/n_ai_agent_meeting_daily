"""pipeCloud02 - Pipecat Voice Agent

This bot uses a cascade pipeline: Speech-to-Text → LLM → Text-to-Speech

Generated by Pipecat CLI

Required AI services:
- Deepgram (Speech-to-Text)
- Groq (LLM)
- Cartesia (Text-to-Speech)

Run the bot using::

    uv run bot.py
"""

"""
pipeCloud02 - Pipecat Voice Agent
"""

import os
import sys
import traceback
import atexit
import signal
import asyncio
import contextlib

from dotenv import load_dotenv
from loguru import logger

from pydantic import ValidationError

from pipecat.pipeline.pipeline import Pipeline
from pipecat.pipeline.runner import PipelineRunner
from pipecat.pipeline.task import PipelineParams, PipelineTask

from pipecat.audio.vad.silero import SileroVADAnalyzer
from pipecat.audio.vad.vad_analyzer import VADParams
from pipecat.audio.turn.smart_turn.local_smart_turn_v3 import LocalSmartTurnAnalyzerV3

from pipecat.transports.daily.transport import DailyTransport, DailyParams
from pipecat.transports.base_transport import BaseTransport

from pipecat.services.deepgram.stt import DeepgramSTTService
from pipecat.services.groq.llm import GroqLLMService
from pipecat.services.cartesia.tts import CartesiaTTSService

from pipecat.processors.aggregators.llm_context import LLMContext
from pipecat.processors.aggregators.llm_response_universal import (
    LLMContextAggregatorPair,
)
from pipecat.observers.loggers.debug_log_observer import DebugLogObserver

from pipecat.processors.frameworks.rtvi import (
    RTVIProcessor,
    RTVIObserver,
    RTVIConfig,
)

from daily_room import create_unique_room

from pipecat.frames.frames import LLMRunFrame
from pipecat.runner.types import DailyRunnerArguments, RunnerArguments
from pipecat.runner.run import main

import asyncio

# Remove default logger and add a detailed one
logger.remove()
logger.add(
    sys.stderr, 
    level="DEBUG",  # Change to "TRACE" for even more detail
    format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level:7}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>"
)

# Force detailed logging for the cartesia and websocket modules
import logging
logging.getLogger("pipecat").setLevel(logging.DEBUG)
logging.getLogger("websockets").setLevel(logging.DEBUG)

shutdown_event = asyncio.Event()

load_dotenv(override=True)

PID_FILE = "/tmp/pipecat_daily_bot.pid"

def ensure_single_instance():
    if os.path.exists(PID_FILE):
        logger.error("Pipecat bot already running. Exiting.")
        sys.exit(1)

    with open(PID_FILE, "w") as f:
        f.write(str(os.getpid()))
        
def cleanup():
    if os.path.exists(PID_FILE):
        os.remove(PID_FILE)

def handle_signal(sig, frame):
    if shutdown_event.is_set():
        return
    logger.warning(f"Received signal {sig}, shutting down")
    shutdown_event.set()

signal.signal(signal.SIGINT, handle_signal)
signal.signal(signal.SIGTERM, handle_signal)


# ------------------------------------------------------------------------------
# BOT LOGIC
# ------------------------------------------------------------------------------

async def run_bot(transport: BaseTransport):
    logger.info("Starting bot")

    # STT
    try:
        stt = DeepgramSTTService(
            api_key=os.getenv("DEEPGRAM_API_KEY")
        )
    except Exception as e:
        hand_exception(e, "Error initiating Deepgram STT service")
        raise


    # TTS
    try:
        tts = CartesiaTTSService(
            api_key=os.getenv("CARTESIA_API_KEY"),
            voice_id=os.getenv("CARTESIA_VOICE_ID"),
        )
    except Exception as e:
        hand_exception(e, "Error initiating Cartesia TTS service")
        raise

    # LLM
    try: 
        llm = GroqLLMService(
            model=os.getenv("GROQ_MODEL"),
            api_key=os.getenv("GROQ_API_KEY"),
        )
    except Exception as e:
        hand_exception(e, "Error initiating Groq LLM service")
        raise


    # Conversation context
    messages = [
        {
            "role": "system",
            "content": "You are a friendly AI assistant. Respond naturally and keep your answers conversational.",
        }
    ]

    context = LLMContext(messages)
    context_aggregator = LLMContextAggregatorPair(context)

    # RTVI (0.0.98 compatible)
    rtvi = RTVIProcessor(
        config=RTVIConfig(
            config=[
                {
                    "service": "voice_agent",
                    "options": [],
                }
            ],
            initial_config=[
                {
                    "service": "voice_agent",
                    "options": [],
                }
            ],
        )
    )

    pipeline = Pipeline(
        [
            transport.input(),
            rtvi,
            stt,
            context_aggregator.user(),
            llm,
            tts,  # disabled due to websocket error, may be quota issue
            transport.output(),
            context_aggregator.assistant(),
        ]
    )

    task = PipelineTask(
        pipeline,
        params=PipelineParams(
            enable_metrics=True,
            enable_usage_metrics=True,
        ),
        observers=[
            RTVIObserver(rtvi),
            # DebugLogObserver() # <--- This will log every single frame movement
        ],
        
    )

    @rtvi.event_handler("on_client_ready")
    async def on_client_ready(rtvi):
        await rtvi.set_bot_ready()
        await task.queue_frames([LLMRunFrame()])
    
    @rtvi.event_handler("on_transport_message")
    async def on_rtvi_msg(msg):
        try:
            pass
        except ValidationError:
            logger.debug("Ignoring malformed RTVI message")

    @transport.event_handler("on_client_connected")
    async def on_client_connected(transport, client):
        logger.info("Client connected")

    @transport.event_handler("on_client_disconnected")
    async def on_client_disconnected(transport, client):
        logger.info("Client disconnected")
        await task.cancel()
        
    @transport.event_handler("on_joined")
    async def on_joined(transport, data):
        logger.success(f"Bot joined room {transport.room_url} as participant {data.get('participant', {}).get('id')}")
        
        await transport.send_message({
            "text": "Hello! I’m ready."
        })
    
    @transport.event_handler("on_message")
    async def on_message(transport, message):
        logger.info(f"CHAT MESSAGE RECEIVED: {message}")

    runner = PipelineRunner(handle_sigint=False)
    # await runner.run(task)
    runner_task = asyncio.create_task(runner.run(task))
    return runner, task, runner_task

# ------------------------------------------------------------------------------
# ENTRYPOINT
# ------------------------------------------------------------------------------

# async def bot(runner_args: RunnerArguments):
#     transport = None

#     match runner_args:
#         case DailyRunnerArguments():
#             room_url = await create_unique_room()
#             logger.info(f"meeting room {room_url}")
#             transport = DailyTransport(
#                 room_url,
#                 token=None,
#                 bot_name="Pipecat Bot",
#                 params=DailyParams(
#                     audio_in_enabled=True,
#                     audio_out_enabled=True,
#                     vad_analyzer=SileroVADAnalyzer(
#                         params=VADParams(stop_secs=0.2)
#                     ),
#                     turn_analyzer=LocalSmartTurnAnalyzerV3(),
#                 ),
#             )
#         case _:
#             logger.error(f"Unsupported runner arguments: {type(runner_args)}")
#             return

#     await run_bot(transport)

async def bot():
    transport = None
    runner = None
    task = None
    runner_task = None

    try:
        room_url = await create_unique_room()
        logger.info(f"meeting room {room_url}")

        transport = DailyTransport(
            room_url,
            token=None,
            bot_name="Pipecat Bot",
            params=DailyParams(
                audio_in_enabled=True,
                audio_out_enabled=True,
                vad_analyzer=SileroVADAnalyzer(
                    params=VADParams(stop_secs=0.2)
                ),
                turn_analyzer=LocalSmartTurnAnalyzerV3(),
            ),
        )

        runner, task, runner_task = await run_bot(transport)

        # Block until Ctrl-C / SIGTERM
        await shutdown_event.wait()

    finally:
        logger.info("Triggering exit sequence...")
        
        # 1. Clear the PID file immediately so a new bot can start
        cleanup()

        async def force_shutdown():
            try:
                # Tell the runner to stop (non-blocking signal)
                if runner:
                    logger.debug("Signaling runner to stop...")
                    await runner.stop()
                
                # Close transport (this is often where the hang happens)
                if transport:
                    logger.debug("Closing transport...")
                    await transport.close()
            except Exception as e:
                logger.error(f"Error during graceful shutdown: {e}")

        try:
            # Give the bot 1.5 seconds to clean up nicely
            logger.success("Trying to shutdown gracefully.")
            await asyncio.wait_for(force_shutdown(), timeout=1.5)
            logger.success("Graceful shutdown successful.")
        except asyncio.TimeoutError:
            logger.warning("Shutdown timed out - forcing exit now.")
        except Exception as e:
            logger.error(f"Shutdown encountered an error: {e}")
        finally:
            # THE KILL SWITCH
            # This bypasses the event loop's wait and terminates the process
            logger.info("Final process exit.")
            os._exit(0)


async def shutdown_with_timeout(coro, timeout=2):
    try:
        await asyncio.wait_for(coro, timeout)
    except asyncio.TimeoutError:
        logger.error("Shutdown step timed out")
    except Exception:
        logger.exception("Shutdown step failed")

if __name__ == "__main__":
    ensure_single_instance()

    try:
        asyncio.run(bot())
    except KeyboardInterrupt:
        pass

def hand_exception(e: Exception, msg: str = "An unexpected error occurred", exit_on_error: bool = False):
    """
    Handle exceptions with Loguru, log details, and optionally end the process.
    
    Parameters:
        e (Exception): The exception object.
        msg (str): Business context message.
        exit_on_error (bool): If True, terminate the process after logging.
    """
    error_type = type(e).__name__
    error_message = str(e)
    stack_trace = traceback.format_exc()

    logger.error(f"[Business Context] {msg}")
    logger.error(f"Exception Type: {error_type}")
    logger.error(f"Exception Message: {error_message}")
    logger.error(f"Stack Trace:\n{stack_trace}")

    if exit_on_error:
        logger.critical("Terminating process due to exception.")
        sys.exit(1)  # Exit with non-zero code to indicate failure

    return {
        "business_message": msg,
        "type": error_type,
        "message": error_message,
        "stack_trace": stack_trace
    }

